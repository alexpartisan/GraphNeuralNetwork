
--- [START 2019-07-09_14-30-46] ----------------------------------------------------------------

	@train_customized_gnn.py:  
	set random seed
		SEED = 1562653846
	set cuda environment
		torch.__version__              = 1.1.0
		torch.version.cuda             = 10.0.130
		torch.backends.cudnn.version() = 7501
		os['CUDA_VISIBLE_DEVICES']     = 0
		torch.cuda.device_count()      = 1



	SEED         = 1562653846
	PROJECT_PATH = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/build
	__file__     = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/build/train_customized_gnn.py
	out_dir      = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/results/0709_2

** dataset setting **
batch_size = 16
train_dataset : 
	mode   = train
	split  = train_split_by_mol_0_56668.npy
	csv    = train
	len    = 56668

valid_dataset : 
	mode   = train
	split  = valid_split_by_mol_0_28335.npy
	csv    = train
	len    = 28335


** net setting **
	initial_checkpoint = None
<class '__main__.Net'>

optimizer
  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
schduler
  NullScheduler
lr=0.00100 

** start training here! **
   batch_size =16,  iter_accum=1
                      |--------------- VALID ----------------------------------------------------------------|-- TRAIN/BATCH ---------
                      |std 18.3     4.5     3.1    10.9     3.7     1.3     4.0    3.7  |                    |        | 
rate     iter   epoch |    1JHC,   2JHC,   3JHC,   1JHN,   2JHN,   3JHN,   2JHH,   3JHH |  loss  mae log_mae | loss   | time          
--------------------------------------------------------------------------------------------------------------------------------------

--- [START 2019-07-09_14-31-31] ----------------------------------------------------------------

	@train_customized_gnn.py:  
	set random seed
		SEED = 1562653891
	set cuda environment
		torch.__version__              = 1.1.0
		torch.version.cuda             = 10.0.130
		torch.backends.cudnn.version() = 7501
		os['CUDA_VISIBLE_DEVICES']     = 0
		torch.cuda.device_count()      = 1



	SEED         = 1562653891
	PROJECT_PATH = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/build
	__file__     = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/build/train_customized_gnn.py
	out_dir      = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/results/0709_2

** dataset setting **
batch_size = 16
train_dataset : 
	mode   = train
	split  = train_split_by_mol_0_56668.npy
	csv    = train
	len    = 56668

valid_dataset : 
	mode   = train
	split  = valid_split_by_mol_0_28335.npy
	csv    = train
	len    = 28335


** net setting **
	initial_checkpoint = None
<class '__main__.Net'>

optimizer
  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
schduler
  NullScheduler
lr=0.00100 

** start training here! **
   batch_size =16,  iter_accum=1
                      |--------------- VALID ----------------------------------------------------------------|-- TRAIN/BATCH ---------
                      |std 18.3     4.5     3.1    10.9     3.7     1.3     4.0    3.7  |                    |        | 
rate     iter   epoch |    1JHC,   2JHC,   3JHC,   1JHN,   2JHN,   3JHN,   2JHH,   3JHH |  loss  mae log_mae | loss   | time          
--------------------------------------------------------------------------------------------------------------------------------------
0.00000    0.0*   0.0 |  +4.553, +1.033, +1.308, +3.861, +1.206, +0.095, +2.353, +1.570 | +2.912 21.09 +2.00 | +0.000 |  0 hr 02 min
0.00100    0.5    0.1 |  +1.454, +0.381, +0.700, +1.333, +0.348, -0.184, +0.395, +0.788 | +0.772  2.19 +0.65 | +0.819 |  0 hr 07 min
0.00100    1.0    0.3 |  +0.877, +0.082, +0.481, +0.999, +0.129, -0.288, +0.010, +0.466 | +0.419  1.54 +0.34 | +0.538 |  0 hr 12 min
0.00100    1.5    0.4 |  +0.805, +0.049, +0.330, +0.782, -0.020, -0.427, +0.226, +0.338 | +0.333  1.39 +0.26 | +0.425 |  0 hr 17 min

--- [START 2019-07-09_15-00-54] ----------------------------------------------------------------

	@train_customized_gnn.py:  
	set random seed
		SEED = 1562655654
	set cuda environment
		torch.__version__              = 1.1.0
		torch.version.cuda             = 10.0.130
		torch.backends.cudnn.version() = 7501
		os['CUDA_VISIBLE_DEVICES']     = 0
		torch.cuda.device_count()      = 1



	SEED         = 1562655654
	PROJECT_PATH = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/build
	__file__     = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/build/train_customized_gnn.py
	out_dir      = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/results/0709_2

** dataset setting **
batch_size = 16
train_dataset : 
	mode   = train
	split  = train_split_by_mol_0_56668.npy
	csv    = train
	len    = 56668

valid_dataset : 
	mode   = train
	split  = valid_split_by_mol_0_28335.npy
	csv    = train
	len    = 28335


** net setting **
	initial_checkpoint = None
<class '__main__.Net'>

optimizer
  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
schduler
  NullScheduler
lr=0.00100 

** start training here! **
   batch_size =16,  iter_accum=1
                      |--------------- VALID ----------------------------------------------------------------|-- TRAIN/BATCH ---------
                      |std 18.3     4.5     3.1    10.9     3.7     1.3     4.0    3.7  |                    |        | 
rate     iter   epoch |    1JHC,   2JHC,   3JHC,   1JHN,   2JHN,   3JHN,   2JHH,   3JHH |  loss  mae log_mae | loss   | time          
--------------------------------------------------------------------------------------------------------------------------------------
0.00000    0.0*   0.0 |  +4.554, +1.022, +1.301, +3.859, +1.190, +0.117, +2.349, +1.566 | +2.911 21.08 +1.99 | +0.000 |  0 hr 00 min
0.00100    0.5    0.1 |  +1.427, +0.396, +0.759, +1.228, +0.351, -0.163, +0.385, +0.913 | +0.800  2.18 +0.66 | +0.873 |  0 hr 00 min
0.00100    1.0    0.3 |  +1.161, +0.185, +0.604, +0.994, +0.150, -0.260, +0.241, +0.685 | +0.594  1.76 +0.47 | +0.652 |  0 hr 01 min
0.00100    1.5    0.4 |  +0.947, +0.067, +0.534, +0.957, +0.007, -0.344, +0.121, +0.601 | +0.473  1.58 +0.36 | +0.538 |  0 hr 01 min
0.00100    2.0    0.6 |  +0.924, +0.063, +0.501, +0.910, -0.018, -0.350, +0.014, +0.540 | +0.439  1.52 +0.32 | +0.484 |  0 hr 02 min
0.00100    2.5*   0.7 |  +0.928, +0.027, +0.423, +0.826, -0.142, -0.412, -0.036, +0.468 | +0.390  1.43 +0.26 | +0.410 |  0 hr 02 min
0.00100    3.0    0.8 |  +0.931, -0.060, +0.380, +0.747, -0.166, -0.431, -0.045, +0.398 | +0.351  1.37 +0.22 | +0.404 |  0 hr 03 min
0.00100    3.5    1.0 |  +0.830, -0.069, +0.342, +0.861, -0.191, -0.461, -0.139, +0.333 | +0.297  1.34 +0.19 | +0.317 |  0 hr 03 min
0.00100    4.0    1.1 |  +0.742, -0.105, +0.309, +0.739, -0.189, -0.465, -0.220, +0.282 | +0.244  1.26 +0.14 | +0.298 |  0 hr 04 min
0.00100    4.5    1.3 |  +0.675, -0.012, +0.323, +0.644, -0.221, -0.449, -0.174, +0.302 | +0.253  1.23 +0.14 | +0.246 |  0 hr 05 min
0.00100    5.0*   1.4 |  +0.728, -0.118, +0.256, +1.068, -0.264, -0.514, -0.182, +0.214 | +0.217  1.33 +0.15 | +0.240 |  0 hr 05 min
0.00100    5.5    1.6 |  +0.666, -0.137, +0.250, +0.854, -0.304, -0.539, -0.203, +0.187 | +0.186  1.22 +0.10 | +0.204 |  0 hr 06 min
0.00100    6.0    1.7 |  +0.555, -0.183, +0.232, +0.650, -0.315, -0.546, -0.283, +0.146 | +0.131  1.12 +0.03 | +0.220 |  0 hr 06 min
0.00100    6.5    1.8 |  +0.652, -0.155, +0.210, +0.617, -0.303, -0.561, -0.280, +0.134 | +0.150  1.13 +0.04 | +0.160 |  0 hr 07 min
0.00100    7.0    2.0 |  +0.566, -0.182, +0.220, +0.615, -0.336, -0.575, -0.344, +0.113 | +0.121  1.10 +0.01 | +0.177 |  0 hr 07 min
0.00100    7.5*   2.1 |  +0.614, -0.187, +0.194, +0.590, -0.354, -0.583, -0.306, +0.098 | +0.122  1.10 +0.01 | +0.152 |  0 hr 08 min
0.00100    8.0    2.3 |  +0.569, -0.223, +0.172, +0.598, -0.371, -0.608, -0.348, +0.075 | +0.090  1.07 -0.02 | +0.131 |  0 hr 08 min
0.00100    8.5    2.4 |  +0.562, -0.234, +0.194, +0.555, -0.377, -0.623, -0.359, +0.047 | +0.089  1.06 -0.03 | +0.097 |  0 hr 09 min
0.00100    9.0    2.5 |  +0.516, -0.230, +0.146, +0.574, -0.342, -0.618, -0.234, +0.037 | +0.068  1.06 -0.02 | +0.104 |  0 hr 09 min
0.00100    9.5    2.7 |  +0.570, -0.255, +0.154, +0.513, -0.418, -0.634, -0.394, +0.009 | +0.065  1.03 -0.06 | +0.107 |  0 hr 10 min
0.00100   10.0*   2.8 |  +0.469, -0.246, +0.136, +0.493, -0.315, -0.641, -0.395, +0.013 | +0.038  1.01 -0.06 | +0.096 |  0 hr 11 min
0.00100   10.5    3.0 |  +0.484, -0.243, +0.130, +0.510, -0.442, -0.653, -0.266, -0.014 | +0.041  1.02 -0.06 | +0.090 |  0 hr 11 min
0.00100   11.0    3.1 |  +0.503, -0.285, +0.098, +0.634, -0.468, -0.638, -0.428, -0.040 | +0.017  1.02 -0.08 | +0.069 |  0 hr 12 min
0.00100   11.5    3.2 |  +0.509, -0.272, +0.106, +0.467, -0.449, -0.624, -0.416, -0.039 | +0.023  0.99 -0.09 | +0.020 |  0 hr 12 min
0.00100   12.0    3.4 |  +0.462, -0.245, +0.102, +0.505, -0.438, -0.672, -0.436, -0.033 | +0.014  0.99 -0.09 | +0.070 |  0 hr 13 min
0.00100   12.5*   3.5 |  +0.458, -0.277, +0.110, +0.475, -0.432, -0.671, -0.370, -0.035 | +0.012  0.98 -0.09 | +0.011 |  0 hr 13 min
0.00100   13.0    3.7 |  +0.444, -0.292, +0.088, +0.440, -0.473, -0.691, -0.374, -0.061 | -0.006  0.96 -0.11 | +0.028 |  0 hr 14 min
0.00100   13.5    3.8 |  +0.419, -0.301, +0.074, +0.472, -0.498, -0.678, -0.475, -0.084 | -0.027  0.95 -0.13 | +0.036 |  0 hr 14 min
0.00100   14.0    4.0 |  +0.420, -0.285, +0.069, +0.461, -0.453, -0.697, -0.343, -0.047 | -0.013  0.97 -0.11 | +0.025 |  0 hr 15 min
0.00100   14.5    4.1 |  +0.490, -0.283, +0.099, +0.408, -0.487, -0.695, -0.363, -0.105 | +0.005  0.96 -0.12 | +0.025 |  0 hr 15 min
0.00100   15.0*   4.2 |  +0.402, -0.327, +0.054, +0.386, -0.509, -0.695, -0.402, -0.067 | -0.039  0.93 -0.14 | +0.011 |  0 hr 16 min
0.00100   15.5    4.4 |  +0.452, -0.318, +0.045, +0.486, -0.485, -0.721, -0.510, -0.130 | -0.041  0.94 -0.15 | -0.001 |  0 hr 17 min
0.00100   16.0    4.5 |  +0.408, -0.331, +0.042, +0.355, -0.533, -0.704, -0.493, -0.122 | -0.055  0.91 -0.17 | +0.002 |  0 hr 17 min
0.00100   16.5    4.7 |  +0.392, -0.330, +0.033, +0.423, -0.525, -0.713, -0.528, -0.142 | -0.065  0.91 -0.17 | -0.028 |  0 hr 18 min
0.00100   17.0    4.8 |  +0.411, -0.306, +0.040, +0.391, -0.507, -0.733, -0.223, -0.101 | -0.031  0.94 -0.13 | -0.006 |  0 hr 18 min
0.00100   17.5*   4.9 |  +0.373, -0.320, +0.030, +0.401, -0.525, -0.738, -0.293, -0.160 | -0.059  0.92 -0.15 | -0.032 |  0 hr 19 min
0.00100   18.0    5.1 |  +0.369, -0.339, +0.027, +0.460, -0.483, -0.720, -0.446, -0.158 | -0.071  0.92 -0.16 | -0.013 |  0 hr 19 min
0.00100   18.5    5.2 |  +0.348, -0.348, +0.051, +0.400, -0.562, -0.727, -0.344, -0.165 | -0.066  0.91 -0.17 | -0.014 |  0 hr 20 min
0.00100   19.0    5.4 |  +0.380, -0.363, +0.001, +0.421, -0.520, -0.734, -0.540, -0.161 | -0.088  0.90 -0.19 | -0.034 |  0 hr 20 min
0.00100   19.5    5.5 |  +0.374, -0.342, +0.014, +0.433, -0.536, -0.740, -0.539, -0.154 | -0.082  0.90 -0.19 | -0.045 |  0 hr 21 min
0.00100   20.0*   5.6 |  +0.366, -0.364, +0.000, +0.456, -0.547, -0.738, -0.525, -0.164 | -0.093  0.90 -0.19 | -0.015 |  0 hr 22 min
0.00100   20.5    5.8 |  +0.414, -0.355, +0.001, +0.403, -0.528, -0.721, -0.504, -0.179 | -0.080  0.90 -0.18 | -0.070 |  0 hr 22 min
0.00100   21.0    5.9 |  +0.414, -0.292, -0.008, +0.329, -0.551, -0.750, -0.558, -0.200 | -0.077  0.89 -0.20 | -0.072 |  0 hr 23 min
0.00100   21.5    6.1 |  +0.397, -0.328, -0.012, +0.379, -0.552, -0.730, -0.531, -0.197 | -0.088  0.89 -0.20 | -0.050 |  0 hr 23 min
0.00100   22.0    6.2 |  +0.356, -0.272, +0.017, +0.385, -0.438, -0.741, -0.384, -0.129 | -0.058  0.92 -0.15 | -0.069 |  0 hr 24 min
0.00100   22.5*   6.4 |  +0.348, -0.355, +0.003, +0.323, -0.501, -0.754, -0.494, -0.196 | -0.098  0.88 -0.20 | -0.044 |  0 hr 24 min
0.00100   23.0    6.5 |  +0.443, -0.354, -0.027, +0.416, -0.568, -0.758, -0.484, -0.210 | -0.085  0.90 -0.19 | -0.069 |  0 hr 25 min
0.00100   23.5    6.6 |  +0.498, -0.373, -0.018, +0.399, -0.528, -0.774, -0.521, -0.175 | -0.070  0.91 -0.19 | -0.070 |  0 hr 25 min
0.00100   24.0    6.8 |  +0.358, -0.276, -0.033, +0.365, -0.576, -0.776, -0.585, -0.206 | -0.099  0.87 -0.22 | -0.093 |  0 hr 26 min
0.00100   24.5    6.9 |  +0.381, -0.380, -0.038, +0.349, -0.576, -0.772, -0.563, -0.225 | -0.117  0.87 -0.23 | -0.093 |  0 hr 27 min
0.00100   25.0*   7.1 |  +0.459, -0.399, -0.031, +0.326, -0.515, -0.776, -0.552, -0.214 | -0.096  0.88 -0.21 | -0.085 |  0 hr 27 min
0.00100   25.5    7.2 |  +0.373, -0.406, -0.040, +0.352, -0.581, -0.766, -0.577, -0.224 | -0.126  0.86 -0.23 | -0.118 |  0 hr 28 min
0.00100   26.0    7.3 |  +0.330, -0.405, -0.040, +0.307, -0.587, -0.752, -0.553, -0.228 | -0.136  0.85 -0.24 | -0.105 |  0 hr 28 min
0.00100   26.5    7.5 |  +0.310, -0.394, -0.038, +0.357, -0.606, -0.749, -0.606, -0.241 | -0.141  0.85 -0.25 | -0.117 |  0 hr 29 min
0.00100   27.0    7.6 |  +0.280, -0.415, -0.045, +0.293, -0.615, -0.774, -0.586, -0.237 | -0.155  0.83 -0.26 | -0.105 |  0 hr 29 min
0.00100   27.5*   7.8 |  +0.331, -0.379, -0.033, +0.302, -0.556, -0.770, -0.521, -0.234 | -0.127  0.85 -0.23 | -0.113 |  0 hr 30 min
0.00100   28.0    7.9 |  +0.350, -0.404, -0.050, +0.401, -0.562, -0.785, -0.599, -0.258 | -0.139  0.86 -0.24 | -0.107 |  0 hr 30 min
0.00100   28.5    8.0 |  +0.343, -0.393, -0.056, +0.288, -0.597, -0.784, -0.519, -0.228 | -0.135  0.85 -0.24 | -0.133 |  0 hr 31 min
0.00100   29.0    8.2 |  +0.341, -0.388, -0.048, +0.365, -0.577, -0.792, -0.586, -0.248 | -0.137  0.85 -0.24 | -0.095 |  0 hr 31 min
0.00100   29.5    8.3 |  +0.533, -0.399, -0.063, +0.552, -0.651, -0.803, -0.476, -0.251 | -0.085  0.93 -0.19 | -0.099 |  0 hr 32 min
0.00100   30.0*   8.5 |  +0.301, -0.400, -0.056, +0.246, -0.613, -0.789, -0.623, -0.271 | -0.159  0.82 -0.28 | -0.136 |  0 hr 33 min
0.00100   30.5    8.6 |  +0.344, -0.406, -0.048, +0.430, -0.609, -0.793, -0.528, -0.251 | -0.136  0.87 -0.23 | -0.117 |  0 hr 33 min
0.00100   31.0    8.8 |  +0.349, -0.420, -0.045, +0.267, -0.567, -0.797, -0.576, -0.277 | -0.143  0.83 -0.26 | -0.059 |  0 hr 34 min
0.00100   31.5    8.9 |  +0.280, -0.392, -0.055, +0.256, -0.628, -0.802, -0.561, -0.222 | -0.153  0.82 -0.27 | -0.123 |  0 hr 34 min

--- [START 2019-07-09_15-38-16] ----------------------------------------------------------------

	@train_customized_gnn.py:  
	set random seed
		SEED = 1562657896
	set cuda environment
		torch.__version__              = 1.1.0
		torch.version.cuda             = 10.0.130
		torch.backends.cudnn.version() = 7501
		os['CUDA_VISIBLE_DEVICES']     = 0
		torch.cuda.device_count()      = 1



	SEED         = 1562657896
	PROJECT_PATH = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/build
	__file__     = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/build/train_customized_gnn.py
	out_dir      = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/results/0709_2

** dataset setting **
batch_size = 16
train_dataset : 
	mode   = train
	split  = train_split_by_mol_0_56668.npy
	csv    = train
	len    = 56668

valid_dataset : 
	mode   = train
	split  = valid_split_by_mol_0_28335.npy
	csv    = train
	len    = 28335


** net setting **
	initial_checkpoint = None
<class '__main__.Net'>

optimizer
  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
schduler
  NullScheduler
lr=0.00100 

** start training here! **
   batch_size =16,  iter_accum=1
                      |--------------- VALID ----------------------------------------------------------------|-- TRAIN/BATCH ---------
                      |std 18.3     4.5     3.1    10.9     3.7     1.3     4.0    3.7  |                    |        | 
rate     iter   epoch |    1JHC,   2JHC,   3JHC,   1JHN,   2JHN,   3JHN,   2JHH,   3JHH |  loss  mae log_mae | loss   | time          
--------------------------------------------------------------------------------------------------------------------------------------

--- [START 2019-07-09_15-39-07] ----------------------------------------------------------------

	@train_customized_gnn.py:  
	set random seed
		SEED = 1562657947
	set cuda environment
		torch.__version__              = 1.1.0
		torch.version.cuda             = 10.0.130
		torch.backends.cudnn.version() = 7501
		os['CUDA_VISIBLE_DEVICES']     = 0
		torch.cuda.device_count()      = 1



	SEED         = 1562657947
	PROJECT_PATH = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/build
	__file__     = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/build/train_customized_gnn.py
	out_dir      = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/results/0709_2

** dataset setting **
batch_size = 16
train_dataset : 
	mode   = train
	split  = train_split_by_mol_0_56668.npy
	csv    = train
	len    = 56668

valid_dataset : 
	mode   = train
	split  = valid_split_by_mol_0_28335.npy
	csv    = train
	len    = 28335


** net setting **
	initial_checkpoint = None
<class '__main__.Net'>

optimizer
  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
schduler
  NullScheduler
lr=0.00100 

** start training here! **
   batch_size =16,  iter_accum=1
                      |--------------- VALID ----------------------------------------------------------------|-- TRAIN/BATCH ---------
                      |std 18.3     4.5     3.1    10.9     3.7     1.3     4.0    3.7  |                    |        | 
rate     iter   epoch |    1JHC,   2JHC,   3JHC,   1JHN,   2JHN,   3JHN,   2JHH,   3JHH |  loss  mae log_mae | loss   | time          
--------------------------------------------------------------------------------------------------------------------------------------

--- [START 2019-07-09_15-40-06] ----------------------------------------------------------------

	@train_customized_gnn.py:  
	set random seed
		SEED = 1562658006
	set cuda environment
		torch.__version__              = 1.1.0
		torch.version.cuda             = 10.0.130
		torch.backends.cudnn.version() = 7501
		os['CUDA_VISIBLE_DEVICES']     = 0
		torch.cuda.device_count()      = 1



	SEED         = 1562658006
	PROJECT_PATH = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/build
	__file__     = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/build/train_customized_gnn.py
	out_dir      = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/results/0709_2

** dataset setting **
batch_size = 16
train_dataset : 
	mode   = train
	split  = train_split_by_mol_0_56668.npy
	csv    = train
	len    = 56668

valid_dataset : 
	mode   = train
	split  = valid_split_by_mol_0_28335.npy
	csv    = train
	len    = 28335


** net setting **
	initial_checkpoint = None
<class '__main__.Net'>

optimizer
  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
schduler
  NullScheduler
lr=0.00100 

** start training here! **
   batch_size =16,  iter_accum=1
                      |--------------- VALID ----------------------------------------------------------------|-- TRAIN/BATCH ---------
                      |std 18.3     4.5     3.1    10.9     3.7     1.3     4.0    3.7  |                    |        | 
rate     iter   epoch |    1JHC,   2JHC,   3JHC,   1JHN,   2JHN,   3JHN,   2JHH,   3JHH |  loss  mae log_mae | loss   | time          
--------------------------------------------------------------------------------------------------------------------------------------

--- [START 2019-07-09_15-49-43] ----------------------------------------------------------------

	@train_customized_gnn.py:  
	set random seed
		SEED = 1562658583
	set cuda environment
		torch.__version__              = 1.1.0
		torch.version.cuda             = 10.0.130
		torch.backends.cudnn.version() = 7501
		os['CUDA_VISIBLE_DEVICES']     = 0
		torch.cuda.device_count()      = 1



	SEED         = 1562658583
	PROJECT_PATH = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/build
	__file__     = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/build/train_customized_gnn.py
	out_dir      = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/results/0709_2

** dataset setting **
batch_size = 24
train_dataset : 
	mode   = train
	split  = train_split_by_mol_0_56668.npy
	csv    = train
	len    = 56668

valid_dataset : 
	mode   = train
	split  = valid_split_by_mol_0_28335.npy
	csv    = train
	len    = 28335


** net setting **
	initial_checkpoint = None
<class '__main__.Net'>

optimizer
  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
schduler
  NullScheduler
lr=0.00100 

** start training here! **
   batch_size =24,  iter_accum=1
                      |--------------- VALID ----------------------------------------------------------------|-- TRAIN/BATCH ---------
                      |std 18.3     4.5     3.1    10.9     3.7     1.3     4.0    3.7  |                    |        | 
rate     iter   epoch |    1JHC,   2JHC,   3JHC,   1JHN,   2JHN,   3JHN,   2JHH,   3JHH |  loss  mae log_mae | loss   | time          
--------------------------------------------------------------------------------------------------------------------------------------
0.00000    0.0*   0.0 |  +4.554, +1.036, +1.313, +3.861, +1.199, +0.084, +2.351, +1.578 | +2.912 21.09 +2.00 | +0.000 |  0 hr 00 min

--- [START 2019-07-09_15-51-32] ----------------------------------------------------------------

	@train_customized_gnn.py:  
	set random seed
		SEED = 1562658692
	set cuda environment
		torch.__version__              = 1.1.0
		torch.version.cuda             = 10.0.130
		torch.backends.cudnn.version() = 7501
		os['CUDA_VISIBLE_DEVICES']     = 0
		torch.cuda.device_count()      = 1



	SEED         = 1562658692
	PROJECT_PATH = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/build
	__file__     = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/build/train_customized_gnn.py
	out_dir      = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/results/0709_2

** dataset setting **
batch_size = 24
train_dataset : 
	mode   = train
	split  = train_split_by_mol_0_56668.npy
	csv    = train
	len    = 56668

valid_dataset : 
	mode   = train
	split  = valid_split_by_mol_0_28335.npy
	csv    = train
	len    = 28335


** net setting **
	initial_checkpoint = None
<class '__main__.Net'>

optimizer
  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
schduler
  NullScheduler
lr=0.00100 

** start training here! **
   batch_size =24,  iter_accum=1
                      |--------------- VALID ----------------------------------------------------------------|-- TRAIN/BATCH ---------
                      |std 18.3     4.5     3.1    10.9     3.7     1.3     4.0    3.7  |                    |        | 
rate     iter   epoch |    1JHC,   2JHC,   3JHC,   1JHN,   2JHN,   3JHN,   2JHH,   3JHH |  loss  mae log_mae | loss   | time          
--------------------------------------------------------------------------------------------------------------------------------------

--- [START 2019-07-09_15-52-05] ----------------------------------------------------------------

	@train_customized_gnn.py:  
	set random seed
		SEED = 1562658725
	set cuda environment
		torch.__version__              = 1.1.0
		torch.version.cuda             = 10.0.130
		torch.backends.cudnn.version() = 7501
		os['CUDA_VISIBLE_DEVICES']     = 0
		torch.cuda.device_count()      = 1



	SEED         = 1562658725
	PROJECT_PATH = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/build
	__file__     = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/build/train_customized_gnn.py
	out_dir      = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/results/0709_2

** dataset setting **
batch_size = 24
train_dataset : 
	mode   = train
	split  = train_split_by_mol_0_56668.npy
	csv    = train
	len    = 56668

valid_dataset : 
	mode   = train
	split  = valid_split_by_mol_0_28335.npy
	csv    = train
	len    = 28335


** net setting **
	initial_checkpoint = None
<class '__main__.Net'>

optimizer
  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
schduler
  NullScheduler
lr=0.00100 

** start training here! **
   batch_size =24,  iter_accum=1
                      |--------------- VALID ----------------------------------------------------------------|-- TRAIN/BATCH ---------
                      |std 18.3     4.5     3.1    10.9     3.7     1.3     4.0    3.7  |                    |        | 
rate     iter   epoch |    1JHC,   2JHC,   3JHC,   1JHN,   2JHN,   3JHN,   2JHH,   3JHH |  loss  mae log_mae | loss   | time          
--------------------------------------------------------------------------------------------------------------------------------------

--- [START 2019-07-09_15-58-21] ----------------------------------------------------------------

	@train_customized_gnn.py:  
	set random seed
		SEED = 1562659101
	set cuda environment
		torch.__version__              = 1.1.0
		torch.version.cuda             = 10.0.130
		torch.backends.cudnn.version() = 7501
		os['CUDA_VISIBLE_DEVICES']     = 0
		torch.cuda.device_count()      = 1



	SEED         = 1562659101
	PROJECT_PATH = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/build
	__file__     = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/build/train_customized_gnn.py
	out_dir      = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/results/0709_2

** dataset setting **
batch_size = 24
train_dataset : 
	mode   = train
	split  = train_split_by_mol_0_56668.npy
	csv    = train
	len    = 56668

valid_dataset : 
	mode   = train
	split  = valid_split_by_mol_0_28335.npy
	csv    = train
	len    = 28335


** net setting **
	initial_checkpoint = None
<class '__main__.Net'>

optimizer
  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
schduler
  NullScheduler
lr=0.00100 

** start training here! **
   batch_size =24,  iter_accum=1
                      |--------------- VALID ----------------------------------------------------------------|-- TRAIN/BATCH ---------
                      |std 18.3     4.5     3.1    10.9     3.7     1.3     4.0    3.7  |                    |        | 
rate     iter   epoch |    1JHC,   2JHC,   3JHC,   1JHN,   2JHN,   3JHN,   2JHH,   3JHH |  loss  mae log_mae | loss   | time          
--------------------------------------------------------------------------------------------------------------------------------------

--- [START 2019-07-09_15-58-44] ----------------------------------------------------------------

	@train_customized_gnn.py:  
	set random seed
		SEED = 1562659124
	set cuda environment
		torch.__version__              = 1.1.0
		torch.version.cuda             = 10.0.130
		torch.backends.cudnn.version() = 7501
		os['CUDA_VISIBLE_DEVICES']     = 0
		torch.cuda.device_count()      = 1



	SEED         = 1562659124
	PROJECT_PATH = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/build
	__file__     = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/build/train_customized_gnn.py
	out_dir      = /home/alexpartisan/Work/Data/Competition/CHAMP/GNN/results/0709_2

** dataset setting **
batch_size = 24
train_dataset : 
	mode   = train
	split  = train_split_by_mol_0_56668.npy
	csv    = train
	len    = 56668

valid_dataset : 
	mode   = train
	split  = valid_split_by_mol_0_28335.npy
	csv    = train
	len    = 28335


** net setting **
	initial_checkpoint = None
<class '__main__.Net'>

optimizer
  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
schduler
  NullScheduler
lr=0.00100 

** start training here! **
   batch_size =24,  iter_accum=1
                      |--------------- VALID ----------------------------------------------------------------|-- TRAIN/BATCH ---------
                      |std 18.3     4.5     3.1    10.9     3.7     1.3     4.0    3.7  |                    |        | 
rate     iter   epoch |    1JHC,   2JHC,   3JHC,   1JHN,   2JHN,   3JHN,   2JHH,   3JHH |  loss  mae log_mae | loss   | time          
--------------------------------------------------------------------------------------------------------------------------------------
0.00000    0.0*   0.0 |  +4.554, +1.036, +1.315, +3.861, +1.193, +0.101, +2.351, +1.577 | +2.912 21.10 +2.00 | +0.000 |  0 hr 01 min
0.00100    0.5    0.2 |  +1.094, +0.146, +0.566, +1.261, +0.196, -0.272, +0.178, +0.654 | +0.555  1.82 +0.48 | +0.681 |  0 hr 02 min
0.00100    1.0    0.4 |  +0.848, -0.052, +0.392, +1.033, -0.066, -0.411, -0.118, +0.440 | +0.343  1.45 +0.26 | +0.434 |  0 hr 04 min
0.00100    1.5    0.6 |  +0.670, -0.167, +0.282, +0.862, -0.152, -0.507, -0.231, +0.247 | +0.204  1.25 +0.13 | +0.306 |  0 hr 05 min
0.00100    2.0    0.8 |  +0.660, -0.183, +0.195, +0.646, -0.260, -0.601, -0.209, +0.089 | +0.142  1.14 +0.04 | +0.183 |  0 hr 07 min
0.00100    2.5*   1.1 |  +0.460, -0.315, +0.098, +0.560, -0.337, -0.642, -0.478, -0.080 | -0.003  0.99 -0.09 | +0.104 |  0 hr 09 min
0.00100    3.0    1.3 |  +0.430, -0.358, +0.077, +0.594, -0.421, -0.669, -0.391, -0.104 | -0.025  0.98 -0.11 | +0.072 |  0 hr 10 min
0.00100    3.5    1.5 |  +0.421, -0.347, +0.037, +0.481, -0.486, -0.724, -0.465, -0.167 | -0.055  0.93 -0.16 | +0.050 |  0 hr 12 min
0.00100    4.0    1.7 |  +0.378, -0.312, -0.001, +0.552, -0.528, -0.757, -0.538, -0.246 | -0.085  0.92 -0.18 | -0.034 |  0 hr 14 min
0.00100    4.5    1.9 |  +0.471, -0.452, -0.042, +0.437, -0.520, -0.788, -0.525, -0.296 | -0.108  0.89 -0.21 | -0.059 |  0 hr 15 min
0.00100    5.0*   2.1 |  +0.354, -0.428, -0.075, +0.399, -0.568, -0.833, -0.599, -0.255 | -0.149  0.85 -0.25 | -0.122 |  0 hr 17 min
0.00100    5.5    2.3 |  +0.288, -0.394, -0.070, +0.333, -0.651, -0.817, -0.233, -0.288 | -0.139  0.86 -0.23 | -0.134 |  0 hr 19 min
0.00100    6.0    2.5 |  +0.275, -0.505, -0.116, +0.383, -0.683, -0.861, -0.540, -0.349 | -0.206  0.81 -0.30 | -0.140 |  0 hr 20 min
0.00100    6.5    2.8 |  +0.402, -0.517, -0.150, +0.249, -0.652, -0.888, -0.625, -0.369 | -0.196  0.80 -0.32 | -0.175 |  0 hr 22 min
0.00100    7.0    3.0 |  +0.313, -0.520, -0.165, +0.335, -0.710, -0.889, -0.566, -0.369 | -0.222  0.80 -0.32 | -0.194 |  0 hr 23 min
0.00100    7.5*   3.2 |  +0.323, -0.550, -0.176, +0.389, -0.740, -0.907, -0.659, -0.390 | -0.236  0.79 -0.34 | -0.218 |  0 hr 25 min
0.00100    8.0    3.4 |  +0.171, -0.554, -0.197, +0.159, -0.734, -0.883, -0.730, -0.438 | -0.295  0.72 -0.40 | -0.211 |  0 hr 27 min
0.00100    8.5    3.6 |  +0.179, -0.538, -0.215, +0.270, -0.743, -0.937, -0.637, -0.389 | -0.286  0.75 -0.38 | -0.264 |  0 hr 28 min
0.00100    9.0    3.8 |  +0.149, -0.607, -0.235, +0.203, -0.755, -0.970, -0.705, -0.483 | -0.329  0.71 -0.43 | -0.284 |  0 hr 30 min
0.00100    9.5    4.0 |  +0.134, -0.612, -0.250, +0.374, -0.777, -0.975, -0.792, -0.488 | -0.342  0.73 -0.42 | -0.308 |  0 hr 32 min
0.00100   10.0*   4.2 |  +0.192, -0.483, -0.223, +0.194, -0.777, -0.988, -0.689, -0.466 | -0.288  0.73 -0.40 | -0.304 |  0 hr 33 min
0.00100   10.5    4.4 |  +0.155, -0.594, -0.264, +0.110, -0.812, -1.001, -0.817, -0.528 | -0.349  0.68 -0.47 | -0.294 |  0 hr 35 min
0.00100   11.0    4.7 |  +0.113, -0.636, -0.248, +0.109, -0.835, -0.989, -0.789, -0.543 | -0.362  0.67 -0.48 | -0.309 |  0 hr 37 min
0.00100   11.5    4.9 |  +0.071, -0.653, -0.296, +0.139, -0.817, -1.020, -0.696, -0.491 | -0.382  0.68 -0.47 | -0.344 |  0 hr 38 min
0.00100   12.0    5.1 |  +0.082, -0.599, -0.263, +0.070, -0.871, -1.033, -0.831, -0.525 | -0.370  0.66 -0.50 | -0.338 |  0 hr 40 min
0.00100   12.5*   5.3 |  +0.056, -0.677, -0.291, +0.078, -0.827, -0.994, -0.827, -0.575 | -0.405  0.65 -0.51 | -0.337 |  0 hr 42 min
0.00100   13.0    5.5 |  +0.097, -0.685, -0.315, +0.065, -0.850, -1.033, -0.833, -0.569 | -0.406  0.65 -0.52 | -0.354 |  0 hr 43 min
0.00100   13.5    5.7 |  +0.010, -0.690, -0.336, +0.031, -0.893, -1.002, -0.744, -0.508 | -0.424  0.64 -0.52 | -0.390 |  0 hr 45 min
0.00100   14.0    5.9 |  +0.099, -0.655, -0.327, +0.091, -0.905, -0.984, -0.831, -0.580 | -0.405  0.65 -0.51 | -0.353 |  0 hr 47 min
0.00100   14.5    6.1 |  +0.069, -0.705, -0.355, +0.152, -0.888, -1.065, -0.818, -0.607 | -0.434  0.65 -0.53 | -0.403 |  0 hr 48 min
0.00100   15.0*   6.4 |  +0.024, -0.701, -0.356, +0.076, -0.858, -1.072, -0.877, -0.599 | -0.448  0.63 -0.55 | -0.383 |  0 hr 50 min
0.00100   15.5    6.6 |  -0.008, -0.687, -0.364, +0.038, -0.920, -1.050, -0.808, -0.627 | -0.456  0.62 -0.55 | -0.401 |  0 hr 52 min
0.00100   16.0    6.8 |  +0.018, -0.700, -0.362, +0.020, -0.960, -1.103, -0.893, -0.659 | -0.462  0.61 -0.58 | -0.387 |  0 hr 53 min
0.00100   16.5    7.0 |  +0.072, -0.670, -0.355, +0.096, -0.912, -1.067, -0.742, -0.625 | -0.425  0.64 -0.53 | -0.446 |  0 hr 55 min
0.00100   17.0    7.2 |  -0.010, -0.720, -0.371, +0.060, -0.924, -1.051, -0.914, -0.664 | -0.475  0.61 -0.57 | -0.424 |  0 hr 56 min
0.00100   17.5*   7.4 |  +0.195, -0.720, -0.351, +0.093, -0.912, -1.043, -0.711, -0.508 | -0.386  0.67 -0.49 | -0.433 |  0 hr 58 min
0.00100   18.0    7.6 |  -0.023, -0.728, -0.387, -0.051, -0.875, -1.113, -0.910, -0.659 | -0.487  0.59 -0.59 | -0.464 |  1 hr 00 min
0.00100   18.5    7.8 |  -0.015, -0.747, -0.415, +0.075, -0.911, -1.103, -0.882, -0.629 | -0.493  0.61 -0.58 | -0.468 |  1 hr 01 min
0.00100   19.0    8.0 |  -0.018, -0.746, -0.415, -0.044, -0.938, -1.124, -0.942, -0.695 | -0.506  0.58 -0.62 | -0.485 |  1 hr 03 min
0.00100   19.5    8.3 |  +0.066, -0.706, -0.422, +0.076, -0.961, -1.095, -0.916, -0.685 | -0.474  0.61 -0.58 | -0.456 |  1 hr 05 min
0.00100   20.0*   8.5 |  -0.035, -0.732, -0.427, -0.034, -0.997, -1.119, -0.670, -0.691 | -0.495  0.60 -0.59 | -0.454 |  1 hr 06 min
0.00100   20.5    8.7 |  +0.008, -0.693, -0.418, +0.095, -0.971, -1.087, -0.886, -0.597 | -0.474  0.62 -0.57 | -0.438 |  1 hr 08 min
0.00100   21.0    8.9 |  +0.039, -0.735, -0.429, +0.071, -0.963, -1.134, -0.890, -0.661 | -0.487  0.61 -0.59 | -0.462 |  1 hr 10 min
0.00100   21.5    9.1 |  -0.049, -0.783, -0.419, -0.074, -0.996, -1.150, -0.941, -0.712 | -0.526  0.57 -0.64 | -0.482 |  1 hr 11 min
0.00100   22.0    9.3 |  -0.058, -0.795, -0.435, -0.106, -0.938, -1.152, -0.965, -0.643 | -0.529  0.57 -0.64 | -0.472 |  1 hr 13 min
0.00100   22.5*   9.5 |  -0.043, -0.786, -0.443, +0.009, -0.971, -1.110, -0.974, -0.669 | -0.528  0.58 -0.62 | -0.508 |  1 hr 15 min
0.00100   23.0    9.7 |  -0.088, -0.743, -0.432, -0.035, -0.967, -1.123, -0.944, -0.663 | -0.525  0.58 -0.62 | -0.525 |  1 hr 16 min
0.00100   23.5   10.0 |  -0.070, -0.797, -0.458, -0.054, -0.992, -1.118, -0.943, -0.725 | -0.548  0.57 -0.64 | -0.479 |  1 hr 18 min
0.00100   24.0   10.2 |  +0.033, -0.686, -0.466, -0.031, -1.044, -1.134, -0.941, -0.639 | -0.494  0.59 -0.61 | -0.521 |  1 hr 19 min
0.00100   24.5   10.4 |  -0.070, -0.796, -0.448, -0.010, -0.995, -1.166, -0.889, -0.721 | -0.541  0.57 -0.64 | -0.541 |  1 hr 21 min
0.00100   25.0*  10.6 |  -0.055, -0.762, -0.452, -0.062, -0.982, -1.182, -0.890, -0.657 | -0.526  0.57 -0.63 | -0.464 |  1 hr 23 min
0.00100   25.5   10.8 |  -0.065, -0.794, -0.448, -0.077, -1.025, -1.181, -0.903, -0.699 | -0.540  0.57 -0.65 | -0.536 |  1 hr 24 min
0.00100   26.0   11.0 |  -0.110, -0.806, -0.433, +0.019, -1.047, -1.181, -1.019, -0.705 | -0.553  0.57 -0.66 | -0.525 |  1 hr 26 min
0.00100   26.5   11.2 |  -0.003, -0.772, -0.463, -0.099, -1.005, -1.154, -0.867, -0.721 | -0.524  0.57 -0.64 | -0.525 |  1 hr 28 min
0.00100   27.0   11.4 |  -0.073, -0.835, -0.458, +0.087, -1.050, -1.170, -0.989, -0.755 | -0.561  0.57 -0.66 | -0.556 |  1 hr 29 min
0.00100   27.5*  11.6 |  -0.056, -0.812, -0.477, -0.154, -1.075, -1.161, -1.000, -0.717 | -0.560  0.55 -0.68 | -0.530 |  1 hr 31 min
0.00100   28.0   11.9 |  -0.091, -0.833, -0.499, -0.108, -1.060, -1.193, -1.023, -0.770 | -0.587  0.54 -0.70 | -0.563 |  1 hr 33 min
0.00100   28.5   12.1 |  -0.149, -0.841, -0.496, -0.120, -1.075, -1.209, -1.062, -0.761 | -0.604  0.53 -0.71 | -0.556 |  1 hr 34 min
0.00100   29.0   12.3 |  -0.096, -0.837, -0.505, -0.107, -1.055, -1.188, -0.964, -0.772 | -0.588  0.54 -0.69 | -0.560 |  1 hr 36 min
0.00100   29.5   12.5 |  -0.110, -0.841, -0.486, -0.082, -1.010, -1.197, -1.010, -0.728 | -0.582  0.55 -0.68 | -0.524 |  1 hr 38 min
0.00100   30.0*  12.7 |  -0.109, -0.844, -0.506, +0.152, -1.051, -1.201, -1.021, -0.777 | -0.593  0.57 -0.67 | -0.568 |  1 hr 39 min
0.00100   30.5   12.9 |  -0.023, -0.790, -0.519, -0.050, -1.058, -1.199, -0.783, -0.760 | -0.552  0.57 -0.65 | -0.579 |  1 hr 41 min
0.00100   31.0   13.1 |  -0.125, -0.846, -0.499, -0.084, -1.060, -1.168, -0.903, -0.739 | -0.587  0.55 -0.68 | -0.567 |  1 hr 42 min
0.00100   31.5   13.3 |  -0.142, -0.847, -0.525, -0.180, -1.063, -1.204, -1.078, -0.799 | -0.619  0.52 -0.73 | -0.586 |  1 hr 44 min
0.00100   32.0   13.6 |  -0.115, -0.865, -0.505, -0.122, -1.028, -1.172, -0.944, -0.766 | -0.596  0.54 -0.69 | -0.576 |  1 hr 46 min
0.00100   32.5*  13.8 |  -0.053, -0.798, -0.509, -0.056, -1.026, -1.180, -1.033, -0.727 | -0.568  0.56 -0.67 | -0.590 |  1 hr 47 min
0.00100   33.0   14.0 |  -0.127, -0.864, -0.511, -0.091, -1.086, -1.187, -1.044, -0.760 | -0.606  0.53 -0.71 | -0.597 |  1 hr 49 min
0.00100   33.5   14.2 |  -0.138, -0.856, -0.518, -0.083, -1.064, -1.180, -1.048, -0.773 | -0.611  0.53 -0.71 | -0.594 |  1 hr 51 min
0.00100   34.0   14.4 |  -0.148, -0.863, -0.527, -0.135, -1.083, -1.177, -0.867, -0.674 | -0.596  0.54 -0.68 | -0.618 |  1 hr 52 min
0.00100   34.5   14.6 |  -0.164, -0.850, -0.536, -0.169, -1.113, -1.209, -1.029, -0.805 | -0.628  0.52 -0.73 | -0.593 |  1 hr 54 min
0.00100   35.0*  14.8 |  -0.105, -0.853, -0.526, +0.098, -1.100, -1.213, -0.994, -0.798 | -0.602  0.56 -0.69 | -0.580 |  1 hr 56 min
0.00100   35.5   15.0 |  -0.090, -0.878, -0.540, -0.195, -1.065, -1.220, -1.062, -0.796 | -0.617  0.52 -0.73 | -0.560 |  1 hr 57 min
0.00100   36.0   15.2 |  -0.180, -0.879, -0.543, -0.128, -1.108, -1.203, -1.086, -0.815 | -0.643  0.52 -0.74 | -0.604 |  1 hr 59 min
0.00100   36.5   15.5 |  -0.186, -0.878, -0.524, -0.149, -1.117, -1.186, -0.994, -0.791 | -0.630  0.52 -0.73 | -0.589 |  2 hr 00 min
0.00100   37.0   15.7 |  -0.061, -0.863, -0.546, -0.149, -1.111, -1.144, -0.966, -0.786 | -0.600  0.54 -0.70 | -0.584 |  2 hr 02 min
0.00100   37.5*  15.9 |  -0.093, -0.841, -0.556, -0.079, -1.126, -1.149, -1.084, -0.796 | -0.614  0.53 -0.72 | -0.607 |  2 hr 04 min
0.00100   38.0   16.1 |  -0.154, -0.856, -0.552, -0.098, -1.102, -1.192, -0.797, -0.811 | -0.616  0.54 -0.70 | -0.608 |  2 hr 05 min
0.00100   38.5   16.3 |  -0.201, -0.888, -0.570, -0.174, -1.120, -1.216, -1.033, -0.826 | -0.659  0.51 -0.75 | -0.624 |  2 hr 07 min
0.00100   39.0   16.5 |  -0.121, -0.889, -0.568, -0.174, -1.145, -1.248, -1.102, -0.781 | -0.638  0.51 -0.75 | -0.619 |  2 hr 09 min
0.00100   39.5   16.7 |  -0.180, -0.881, -0.548, -0.149, -1.073, -1.206, -1.048, -0.784 | -0.639  0.52 -0.73 | -0.611 |  2 hr 10 min
0.00100   40.0*  16.9 |  -0.093, -0.885, -0.543, -0.243, -1.136, -1.205, -1.102, -0.766 | -0.620  0.51 -0.75 | -0.637 |  2 hr 12 min
0.00100   40.5   17.2 |  -0.127, -0.887, -0.524, -0.223, -1.118, -1.221, -0.988, -0.812 | -0.621  0.52 -0.74 | -0.631 |  2 hr 14 min
0.00100   41.0   17.4 |  -0.184, -0.901, -0.565, -0.191, -1.155, -1.252, -1.107, -0.830 | -0.662  0.50 -0.77 | -0.635 |  2 hr 15 min
